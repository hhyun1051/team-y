"""
Office Automation Workflow - LangGraph StateGraph ê¸°ë°˜

ë…¸ë“œ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°:
1. classify_intent â†’ ì˜ë„ ë¶„ë¥˜
2. help / delivery_subgraph / product_subgraph / aluminum_subgraph â†’ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì²˜ë¦¬
"""

import os
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage

# Langfuse í†µí•©
from langfuse import get_client
from langfuse.langchain import CallbackHandler

# Local imports
from .state import OfficeAutomationState
from .utils.intent_classifier import IntentClassifier
from .utils.parsers import DeliveryParser, ProductOrderParser
from .utils.document_generator import DocumentGenerator
from .utils.tools.aluminum_calculator import (
    calculate_aluminum_price_square_pipe,
    calculate_aluminum_price_round_pipe,
    calculate_aluminum_price_angle,
    calculate_aluminum_price_flat_bar,
    calculate_aluminum_price_round_bar,
    calculate_aluminum_price_channel,
    calculate_price_from_weight_and_price_per_kg,
    calculate_price_per_kg_from_unit_price_and_weight,
)
from .subgraphs import create_delivery_subgraph, create_product_subgraph, create_aluminum_subgraph
from ..middleware import LangfuseToolLoggingMiddleware


class OfficeAutomationGraph:
    """ì‚¬ë¬´ ìë™í™” ê·¸ë˜í”„ (LangGraph StateGraph ê¸°ë°˜)"""

    def __init__(
        self,
        model_name: str = "gpt-4o-mini",
        temperature: float = 0.0,
        use_langfuse: bool = True,
    ):
        """
        OfficeAutomationGraph ì´ˆê¸°í™”

        Args:
            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸
            temperature: ëª¨ë¸ temperature
            use_langfuse: Langfuse ë¡œê¹… ì‚¬ìš© ì—¬ë¶€
        """
        print(f"[ğŸ¤–] Initializing Office Automation Graph (StateGraph)...")

        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        load_dotenv()

        self.model_name = model_name
        self.temperature = temperature
        self.use_langfuse = use_langfuse

        # Langfuse ì´ˆê¸°í™”
        self._init_langfuse()

        # Parser ì´ˆê¸°í™”
        self.intent_classifier = IntentClassifier(model_name=model_name, temperature=temperature)
        self.delivery_parser = DeliveryParser(model_name=model_name, temperature=temperature)
        self.product_parser = ProductOrderParser(model_name=model_name, temperature=temperature)

        # ì²´í¬í¬ì¸í„° (ë©”ëª¨ë¦¬ ì €ì¥)
        self.checkpointer = MemorySaver()

        # Middleware ì„¤ì • (AluminumSubGraphìš©)
        aluminum_middlewares = []
        if self.use_langfuse and self.langfuse_client:
            langfuse_middleware = LangfuseToolLoggingMiddleware(
                langfuse_client=self.langfuse_client,
                verbose=True,
                log_errors=True
            )
            aluminum_middlewares.append(langfuse_middleware)

        # ì•Œë£¨ë¯¸ëŠ„ ê³„ì‚° ë„êµ¬ ë¦¬ìŠ¤íŠ¸
        aluminum_tools = [
            calculate_aluminum_price_square_pipe,
            calculate_aluminum_price_round_pipe,
            calculate_aluminum_price_angle,
            calculate_aluminum_price_flat_bar,
            calculate_aluminum_price_round_bar,
            calculate_aluminum_price_channel,
            calculate_price_from_weight_and_price_per_kg,
            calculate_price_per_kg_from_unit_price_and_weight,
        ]

        # ì„œë¸Œê·¸ë˜í”„ ìƒì„±
        print(f"[ğŸ”¨] Creating subgraphs...")
        self.delivery_subgraph = create_delivery_subgraph(
            checkpointer=self.checkpointer,
            delivery_parser=self.delivery_parser,
            document_generator=DocumentGenerator
        )
        self.product_subgraph = create_product_subgraph(
            checkpointer=self.checkpointer,
            product_parser=self.product_parser,
            document_generator=DocumentGenerator
        )
        self.aluminum_subgraph = create_aluminum_subgraph(
            model_name=model_name,
            temperature=temperature,
            aluminum_tools=aluminum_tools,
            middleware=aluminum_middlewares if aluminum_middlewares else None
        )

        # ë©”ì¸ ê·¸ë˜í”„ ë¹Œë“œ
        self.graph = self._build_graph()

        print(f"[âœ…] Office Automation Graph initialized successfully")

    def _init_langfuse(self):
        """Langfuse ì´ˆê¸°í™”"""
        if not self.use_langfuse:
            self.langfuse_client = None
            return

        try:
            # Langfuse v3: singleton client ì‚¬ìš©
            self.langfuse_client = get_client()
            print(f"[âœ…] Langfuse initialized: {os.getenv('LANGFUSE_BASE_URL', 'default')}")
        except Exception as e:
            print(f"[âš ï¸] Langfuse initialization failed: {e}")
            self.langfuse_client = None

    def _build_graph(self) -> StateGraph:
        """ë©”ì¸ ê·¸ë˜í”„ ë¹Œë“œ"""
        workflow = StateGraph(OfficeAutomationState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("classify_intent", self._classify_intent_node)
        workflow.add_node("help", self._help_node)
        workflow.add_node("delivery_subgraph", self.delivery_subgraph)
        workflow.add_node("product_subgraph", self.product_subgraph)
        workflow.add_node("aluminum_subgraph", self.aluminum_subgraph)

        # ì—£ì§€ ì—°ê²°
        workflow.set_entry_point("classify_intent")

        # classify_intent í›„: ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "classify_intent",
            self._route_by_scenario,
            {
                "help": "help",
                "delivery": "delivery_subgraph",
                "product_order": "product_subgraph",
                "aluminum_calculation": "aluminum_subgraph",
            }
        )

        # ê° ë…¸ë“œ â†’ END
        workflow.add_edge("help", END)
        workflow.add_edge("delivery_subgraph", END)
        workflow.add_edge("product_subgraph", END)
        workflow.add_edge("aluminum_subgraph", END)

        # Compile
        return workflow.compile(checkpointer=self.checkpointer)

    # ========================================================================
    # ë…¸ë“œ í•¨ìˆ˜ë“¤
    # ========================================================================

    def _classify_intent_node(self, state: OfficeAutomationState) -> Dict[str, Any]:
        """
        ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ (ë©€í‹°í„´ ì§€ì›)

        active_scenarioê°€ ìˆìœ¼ë©´ ì¬ë¶„ë¥˜í•˜ì§€ ì•Šê³  í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ ìœ ì§€

        Args:
            state: í˜„ì¬ ìƒíƒœ

        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (scenario, confidence)
        """
        # ë©€í‹°í„´ ëŒ€í™”: active_scenarioê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        active_scenario = state.get("active_scenario")
        if active_scenario:
            print(f"[ğŸ”’] Active scenario locked: {active_scenario} (multi-turn mode)")
            return {
                "scenario": active_scenario,
                "confidence": 1.0  # Active scenarioëŠ” 100% ì‹ ë¢°ë„
            }

        # active_scenarioê°€ ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ì˜ë„ ë¶„ë¥˜
        raw_input = state.get("raw_input", "")
        print(f"[ğŸ”] Classifying intent: {raw_input[:50]}...")

        intent = self.intent_classifier.classify(raw_input)
        print(f"[ğŸ¯] Intent: {intent.scenario} (confidence: {intent.confidence:.2f})")

        return {
            "scenario": intent.scenario,
            "confidence": intent.confidence
        }

    def _route_by_scenario(self, state: OfficeAutomationState) -> str:
        """
        ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¼ìš°íŒ… í•¨ìˆ˜

        Args:
            state: í˜„ì¬ ìƒíƒœ

        Returns:
            ë‹¤ìŒ ë…¸ë“œ ì´ë¦„
        """
        scenario = state.get("scenario")
        print(f"[ğŸ§­] Routing to: {scenario}")
        return scenario

    def _help_node(self, state: OfficeAutomationState) -> Dict[str, Any]:
        """
        ë„ì›€ë§ ë…¸ë“œ

        Args:
            state: í˜„ì¬ ìƒíƒœ

        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (messages)
        """
        print(f"[â„¹ï¸] Providing help message")

        help_message = """ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì‚¬ë¬´ ìë™í™” ë´‡ì…ë‹ˆë‹¤. ğŸ‘‹

ì œê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

**1ï¸âƒ£ ìš´ì†¡ì¥ ìƒì„±**
ë°°ì†¡ ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ ìš´ì†¡ì¥ PDFë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.

í•„ìš”í•œ ì •ë³´:
- í•˜ì°¨ì§€ (íšŒì‚¬ ì´ë¦„)
- ì£¼ì†Œ (ìƒì„¸ì£¼ì†Œ í¬í•¨)
- ì—°ë½ì²˜ (010-XXXX-XXXX í˜•ì‹)
- ì§€ë¶ˆë°©ë²• (ì°©ë¶ˆ ë˜ëŠ” ì„ ë¶ˆ)

**ì…ë ¥ ì˜ˆì‹œ:**
`(ì£¼)ì‚¼ì„±ì „ì ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123 010-1234-5678 ì°©ë¶ˆ 35000ì›`

---

**2ï¸âƒ£ ê±°ë˜ëª…ì„¸ì„œ ìƒì„±**
ì œí’ˆ ì£¼ë¬¸ ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ ê±°ë˜ëª…ì„¸ì„œ PDFë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.

í•„ìš”í•œ ì •ë³´:
- ê±°ë˜ì²˜ (ì˜ˆ: (ì£¼)ì‚¼ì„±ì „ì)
- í’ˆëª© (ì œí’ˆëª…)
- ìˆ˜ëŸ‰ (ê°œìˆ˜)
- ë‹¨ê°€ (ì› ë‹¨ìœ„)

**ì…ë ¥ ì˜ˆì‹œ:**
`ê±°ë˜ì²˜ (ì£¼)ì‚¼ì„±ì „ì, ì•Œë£¨ë¯¸ëŠ„ ì›íŒŒì´í”„, 10ê°œ, ê°œë‹¹ 50000ì›`

---

**3ï¸âƒ£ ì•Œë£¨ë¯¸ëŠ„ ë‹¨ê°€ ê³„ì‚°**
ì•Œë£¨ë¯¸ëŠ„ ì œí’ˆì˜ ë‹¨ê°€ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ë“œë¦½ë‹ˆë‹¤.

ì§€ì› ì œí’ˆ:
- ì‚¬ê°íŒŒì´í”„, ì›íŒŒì´í”„, ì•µê¸€, í‰ì² , í™˜ë´‰, ì°¬ë„¬

**ì…ë ¥ ì˜ˆì‹œ:**
- `ì‚¬ê°íŒŒì´í”„ 50x30x2t, 3m`
- `ì›íŒŒì´í”„ Ã˜40x2t, 6m`
- `ì¤‘ëŸ‰ 2.5kg, kgë‹¹ 6000ì›`

---

**ğŸ“Œ ì‚¬ìš© ë°©ë²•:**
1. ìœ„ ì •ë³´ë¥¼ ì…ë ¥í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤
2. ë¬¸ì„œ ìƒì„±ì€ í™•ì¸ ë²„íŠ¼(ìŠ¹ì¸/ê±°ì ˆ/í¸ì§‘)ì´ í‘œì‹œë©ë‹ˆë‹¤
3. ì•Œë£¨ë¯¸ëŠ„ ê³„ì‚°ì€ ì¦‰ì‹œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤

ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"""

        return {
            "messages": [AIMessage(content=help_message)]
        }

    # ========================================================================
    # ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤
    # ========================================================================

    def invoke(
        self,
        raw_input: str,
        input_type: str = "text",
        discord_user_id: Optional[str] = None,
        discord_channel_id: Optional[str] = None,
        thread_id: str = "default",
    ) -> Dict[str, Any]:
        """
        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            raw_input: ì…ë ¥ í…ìŠ¤íŠ¸ (ì›ë³¸ ë˜ëŠ” ìŒì„± ë³€í™˜)
            input_type: ì…ë ¥ íƒ€ì… ("text" ë˜ëŠ” "voice")
            discord_user_id: ë””ìŠ¤ì½”ë“œ ì‚¬ìš©ì ID
            discord_channel_id: ë””ìŠ¤ì½”ë“œ ì±„ë„ ID
            thread_id: ìŠ¤ë ˆë“œ ID (ëŒ€í™” ì„¸ì…˜ ì‹ë³„)

        Returns:
            Graph ì‹¤í–‰ ê²°ê³¼
        """
        print(f"[ğŸ“¤] Invoking graph with thread_id={thread_id}...")

        # Langfuse CallbackHandler ìƒì„±
        callbacks = []
        if self.langfuse_client:
            try:
                langfuse_handler = CallbackHandler()
                callbacks = [langfuse_handler]
            except Exception as e:
                print(f"[âš ï¸] Failed to create Langfuse handler: {e}")

        config = {
            "configurable": {"thread_id": thread_id},
            "callbacks": callbacks,
            "metadata": {
                "langfuse_session_id": thread_id,
                "langfuse_user_id": discord_user_id or "unknown",
                "langfuse_tags": ["office-automation", input_type],
            }
        }

        initial_state = {
            "raw_input": raw_input,
            "input_type": input_type,
            "messages": [HumanMessage(content=raw_input)],
            "discord_user_id": discord_user_id,
            "discord_channel_id": discord_channel_id,
            "thread_id": thread_id,
            "awaiting_approval": False,
        }

        result = self.graph.invoke(initial_state, config)
        print(f"[âœ…] Graph execution completed")
        return result

    def get_state(self, thread_id: str = "default") -> Optional[Dict[str, Any]]:
        """
        íŠ¹ì • ìŠ¤ë ˆë“œì˜ í˜„ì¬ ìƒíƒœ ì¡°íšŒ

        Args:
            thread_id: ìŠ¤ë ˆë“œ ID

        Returns:
            í˜„ì¬ ìƒíƒœ ë˜ëŠ” None
        """
        config = {"configurable": {"thread_id": thread_id}}
        try:
            state = self.graph.get_state(config)
            return state
        except Exception as e:
            print(f"[âš ï¸] Failed to get state: {e}")
            return None

    def resume(
        self,
        decision_type: str,
        reject_message: Optional[str] = None,
        thread_id: str = "default",
    ) -> Dict[str, Any]:
        """
        HITL ìŠ¹ì¸/ê±°ì ˆ í›„ ì›Œí¬í”Œë¡œìš° ì¬ê°œ

        Args:
            decision_type: "approve" ë˜ëŠ” "reject"
            reject_message: rejectì¸ ê²½ìš° ê±°ì ˆ ë©”ì‹œì§€
            thread_id: ìŠ¤ë ˆë“œ ID

        Returns:
            Graph ì‹¤í–‰ ê²°ê³¼
        """
        config = {"configurable": {"thread_id": thread_id}}

        print(f"[ğŸ”„] Resuming graph with decision={decision_type}, thread_id={thread_id}...")

        # í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        state = self.graph.get_state(config)
        if not state:
            print(f"[âŒ] No state found for thread_id={thread_id}")
            return {"error": "No state found"}

        # Subgraph interruptì¸ ê²½ìš°: subgraph state ì—…ë°ì´íŠ¸
        if state.tasks and len(state.tasks) > 0:
            task = state.tasks[0]
            print(f"[ğŸ”] Found interrupted task: {task.name}")

            # Subgraphì˜ state ì—…ë°ì´íŠ¸
            update_values = {
                "approval_decision": decision_type,
                "awaiting_approval": False
            }

            if decision_type == "reject":
                update_values["reject_message"] = reject_message or "ì‚¬ìš©ìê°€ ê±°ì ˆí–ˆìŠµë‹ˆë‹¤."

            # update_stateë¥¼ ì‚¬ìš©í•˜ì—¬ subgraph state ì—…ë°ì´íŠ¸
            print(f"[ğŸ”§] Updating subgraph state: {update_values}")
            self.graph.update_state(task.state, update_values)

            # ê·¸ë˜í”„ ì¬ê°œ (invoke ì—†ì´, ë‹¨ìˆœíˆ Noneìœ¼ë¡œ ì¬ê°œ)
            print(f"[ğŸš€] Invoking graph to resume from interrupt...")
            result = self.graph.invoke(None, config)
        else:
            # Main graph interrupt (ì´ ê²½ìš°ëŠ” ì—†ì–´ì•¼ í•¨)
            print(f"[âš ï¸] No tasks found - updating main graph state")
            updated_values = {
                "approval_decision": decision_type,
                "awaiting_approval": False
            }

            if decision_type == "reject":
                updated_values["reject_message"] = reject_message or "ì‚¬ìš©ìê°€ ê±°ì ˆí–ˆìŠµë‹ˆë‹¤."

            self.graph.update_state(config, updated_values)
            result = self.graph.invoke(None, config)

        print(f"[âœ…] Graph resume completed")
        return result
